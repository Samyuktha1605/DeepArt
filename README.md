# Neural-Style-Transfer
The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). NST builds on the key idea that,
It is possible to separate the style representation and content representations in a CNN, learnt during a computer vision task (for example, an image recognition task).

The aim of this project is to implement Neural Style Transfer by using the technique demonstrated by Gatys et al in his paper “A Neural Algorithm of Artistic Style”. A modification of the algorithm is also done to perform Style Transfer with multiple styles.

This project is implemented in Python using TensorFlow library. The images are converted to tensor datatype which facilitates use of specialized image-processing functions on them efficiently. The image is resized so that maximum dimension is 512 pixels, and the pixel values of image are transformed to the range 0 to 1.

VGG 19 pre-trained neural network is employed in this method. VGG 19 is a convolution neural network trained on an ImageNet for its object recognition and localization. This VGG 19 CNN performs exceptionally well in localization tasks. It can extract various features by taking the feature maps of certain layers while the images are feed into VGG. The Gatys et al. method uses the per-pixel loss function they are mainly content and style loss. They can capture low-level image features. The output is generated by minimizing the loss. The main goal is minimizing loss function and there should be a balance between both the losses to produce high-quality images. This process is slow as it uses backpropagation for updating weights for optimization.
